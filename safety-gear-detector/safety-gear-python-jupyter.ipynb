{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env MODEL = /opt/intel/openvino/deployment_tools/tools/model_downloader/Retail/object_detection/pedestrian/rmnet_ssd/0013/dldt/person-detection-retail-0013.xml\n",
    "%env CONFIG = resources/conf.txt\n",
    "%env CPU_EXTENSION = /opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/libcpu_extension_avx2.so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    " Copyright (c) 2018 Intel Corporation.\n",
    "\n",
    " Permission is hereby granted, free of charge, to any person obtaining\n",
    " a copy of this software and associated documentation files (the\n",
    " \"Software\"), to deal in the Software without restriction, including\n",
    " without limitation the rights to use, copy, modify, merge, publish,\n",
    " distribute, sublicense, and/or sell copies of the Software, and to\n",
    " permit persons to whom the Software is furnished to do so, subject to\n",
    " the following conditions:\n",
    "\n",
    " The above copyright notice and this permission notice shall be\n",
    " included in all copies or substantial portions of the Software.\n",
    "\n",
    " THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n",
    " EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n",
    " MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n",
    " NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n",
    " LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n",
    " OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n",
    " WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from inference import Network\n",
    "\n",
    "# Global vars\n",
    "cpu_extension = ''\n",
    "conf_modelLayers = ''\n",
    "conf_modelWeights = ''\n",
    "targetDevice = \"CPU\"\n",
    "conf_batchSize = 1\n",
    "conf_modelPersonLabel = 1\n",
    "conf_inferConfidenceThreshold = 0.7\n",
    "conf_inFrameViolationsThreshold = 15\n",
    "conf_inFramePeopleThreshold = 5\n",
    "padding = 0.05\n",
    "viol_wk = 0\n",
    "acceptedDevices = ['CPU', 'GPU', 'MYRIAD', 'HETERO:FPGA,CPU', 'HETERO:HDDL,CPU']\n",
    "videos = []\n",
    "name_of_videos = []\n",
    "\n",
    "\n",
    "class Video:\n",
    "    def __init__(self, idx, path):\n",
    "        if path.isnumeric():\n",
    "            self.video = cv2.VideoCapture(int(path))\n",
    "            self.name = \"Cam \" + str(idx)\n",
    "        else:\n",
    "            if os.path.exists(path):\n",
    "                self.video = cv2.VideoCapture(path)\n",
    "                self.name = \"Video \" + str(idx)\n",
    "            else:\n",
    "                print(\"Either wrong input path or empty line is found. Please check the conf.txt file\")\n",
    "                exit(21)\n",
    "        if not self.video.isOpened():\n",
    "            print(\"Couldn't open video: \" + path)\n",
    "            sys.exit(20)\n",
    "        self.height = int(self.video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        self.width = int(self.video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "        self.currentViolationCount = 0\n",
    "        self.currentViolationCountConfidence = 0\n",
    "        self.prevViolationCount = 0\n",
    "        self.totalViolations = 0\n",
    "        self.totalPeopleCount = 0\n",
    "        self.currentPeopleCount = 0\n",
    "        self.currentPeopleCountConfidence = 0\n",
    "        self.prevPeopleCount = 0\n",
    "        self.currentTotalPeopleCount = 0\n",
    "\n",
    "        cv2.namedWindow(self.name, cv2.WINDOW_NORMAL)\n",
    "        self.frame_start_time = datetime.datetime.now()\n",
    "\n",
    "\n",
    "def env_parser():\n",
    "    \"\"\"\n",
    "    Parses the inputs.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    global conf_modelLayers, conf_modelWeights, targetDevice, cpu_extension, videos\n",
    "    if 'MODEL' in os.environ:\n",
    "        conf_modelLayers = os.environ['MODEL']\n",
    "        conf_modelWeights = os.path.splitext(conf_modelLayers)[0] + \".bin\"\n",
    "    else:\n",
    "        print(\"Please provide path for the .xml file.\")\n",
    "        sys.exit(0)\n",
    "    if 'DEVICE' in os.environ:\n",
    "        targetDevice = os.environ['DEVICE']\n",
    "        if targetDevice not in acceptedDevices:\n",
    "            print(\"Selected device, %s not supported.\" % (targetDevice))\n",
    "            sys.exit(12)\n",
    "    if 'CPU_EXTENSION' in os.environ:\n",
    "        cpu_extension = os.environ['CPU_EXTENSION']\n",
    "    if 'CONFIG' in os.environ:\n",
    "        with open(os.environ['CONFIG'], 'r') as cfg:\n",
    "            for cnt, line in enumerate(cfg.read().splitlines()):\n",
    "                vid = Video(cnt, line)\n",
    "                name_of_videos.append([cnt, line])\n",
    "                videos.append([cnt, vid])\n",
    "    else:\n",
    "        print(\"Please provide path for the conf.txt\")\n",
    "        sys.exit(0)\n",
    "\n",
    "\n",
    "def detect_safety_hat(img):\n",
    "    \"\"\"\n",
    "    Detection of the hat of the person.\n",
    "    :param img: Current frame\n",
    "    :return: Boolean value of the detected hat\n",
    "    \"\"\"\n",
    "    lowH = 15\n",
    "    lowS = 65\n",
    "    lowV = 75\n",
    "\n",
    "    highH = 30\n",
    "    highS = 255\n",
    "    highV = 255\n",
    "\n",
    "    crop = 0\n",
    "    height = 15\n",
    "    perc = 8\n",
    "\n",
    "    hsv = np.zeros(1)\n",
    "\n",
    "    try:\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    except cv2.error as e:\n",
    "        print(\"%d %d %d\" % (img.shape))\n",
    "        print(\"%d %d %d\" % (img.shape))\n",
    "        print(e)\n",
    "\n",
    "    threshold_img = cv2.inRange(hsv, (lowH, lowS, lowV), (highH, highS, highV))\n",
    "\n",
    "    x = 0\n",
    "    y = int(threshold_img.shape[0] * crop / 100)\n",
    "    w = int(threshold_img.shape[1])\n",
    "    h = int(threshold_img.shape[0] * height / 100)\n",
    "    img_cropped = threshold_img[y: y + h, x: x + w]\n",
    "\n",
    "    if cv2.countNonZero(threshold_img) < img_cropped.size * perc / 100:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def detect_safety_jacket(img):\n",
    "    \"\"\"\n",
    "    Detection of the safety jacket of the person.\n",
    "    :param img: Current frame\n",
    "    :return: Boolean value of the detected jacket\n",
    "    \"\"\"\n",
    "    lowH = 0\n",
    "    lowS = 150\n",
    "    lowV = 42\n",
    "\n",
    "    highH = 11\n",
    "    highS = 255\n",
    "    highV = 255\n",
    "\n",
    "    crop = 15\n",
    "    height = 40\n",
    "    perc = 23\n",
    "\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    threshold_img = cv2.inRange(hsv, (lowH, lowS, lowV), (highH, highS, highV))\n",
    "\n",
    "    x = 0\n",
    "    y = int(threshold_img.shape[0] * crop / 100)\n",
    "    w = int(threshold_img.shape[1])\n",
    "    h = int(threshold_img.shape[0] * height / 100)\n",
    "    img_cropped = threshold_img[y: y + h, x: x + w]\n",
    "\n",
    "    if cv2.countNonZero(threshold_img) < img_cropped.size * perc / 100:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def detect_workers(workers, frame):\n",
    "    \"\"\"\n",
    "    Detection of the person with the safety guards.\n",
    "    :param workers: Total number of the person in the current frame\n",
    "    :param frame: Current frame\n",
    "    :return: Total violation count of the person\n",
    "    \"\"\"\n",
    "    violations = 0\n",
    "    global viol_wk\n",
    "    for worker in workers:\n",
    "        xmin, ymin, xmax, ymax = worker\n",
    "        crop = frame[ymin:ymax, xmin:xmax]\n",
    "        if 0 not in crop.shape:\n",
    "            if detect_safety_hat(crop):\n",
    "                if detect_safety_jacket(crop):\n",
    "                    cv2.rectangle(frame, (xmin, ymin), (xmax, ymax),\n",
    "                                  (0, 255, 0), 2)\n",
    "                else:\n",
    "                    cv2.rectangle(frame, (xmin, ymin), (xmax, ymax),\n",
    "                                  (0, 0, 255), 2)\n",
    "                    violations += 1\n",
    "                    viol_wk += 1\n",
    "\n",
    "            else:\n",
    "                cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)\n",
    "                violations += 1\n",
    "                viol_wk += 1\n",
    "\n",
    "    return violations\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Load the network and parse the output.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    env_parser()\n",
    "    prevReq = 0\n",
    "    currReq = 1\n",
    "\n",
    "    prevVideo = None\n",
    "    vid_finished = [False] * len(videos)\n",
    "    min_FPS = min([videos[i][1].video.get(cv2.CAP_PROP_FPS) for i in range(len(videos))])\n",
    "    wait_time = int(round(1000 / min_FPS / len(videos)))\n",
    "\n",
    "    # Initialise the class\n",
    "    infer_network = Network()\n",
    "    # Load the network to IE plugin to get shape of input layer\n",
    "    batch_size, channels, model_height, model_width = \\\n",
    "        infer_network.load_model(conf_modelLayers, targetDevice, 1, 1, 2,\n",
    "                                 cpu_extension)[1]\n",
    "\n",
    "    while True:\n",
    "        for index, currVideo in videos:\n",
    "            # Read image from video/cam\n",
    "            vfps = int(round(currVideo.video.get(cv2.CAP_PROP_FPS)))\n",
    "            for i in range(0, int(round(vfps / min_FPS))):\n",
    "                ret, current_img = currVideo.video.read()\n",
    "                if not ret:\n",
    "                    vid_finished[index] = True\n",
    "                    break\n",
    "            if vid_finished[index]:\n",
    "                stream_end_frame = np.zeros((int(currVideo.height), int(currVideo.width), 1),\n",
    "                                               dtype='uint8')\n",
    "                cv2.putText(stream_end_frame, \"Input file {} has ended\".format\n",
    "                (name_of_videos[index][1].split('/')[-1]) ,\n",
    "                            (10, int(currVideo.height/2)),\n",
    "                            cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)\n",
    "                cv2.imshow(currVideo.name, stream_end_frame)\n",
    "                continue\n",
    "            # Transform image to model input\n",
    "            rsImg = cv2.resize(current_img, (model_width, model_height))\n",
    "            rsImg = rsImg.transpose((2, 0, 1))\n",
    "            rsImg = rsImg.reshape(\n",
    "                (batch_size, channels, model_height, model_width))\n",
    "\n",
    "            infer_start_time = datetime.datetime.now()\n",
    "            # Infer current image\n",
    "            infer_network.exec_net(currReq, rsImg)\n",
    "\n",
    "            # Wait for previous request to end\n",
    "            if infer_network.wait(prevReq) == 0:\n",
    "                infer_end_time = (datetime.datetime.now() - infer_start_time) * 1000\n",
    "\n",
    "                in_frame_workers = []\n",
    "\n",
    "                people = 0\n",
    "                result = infer_network.get_output(prevReq)\n",
    "                # Filter output\n",
    "                for obj in result[0][0]:\n",
    "                    if obj[2] > conf_inferConfidenceThreshold:\n",
    "                        xmin = int(obj[3] * prevVideo.width)\n",
    "                        ymin = int(obj[4] * prevVideo.height)\n",
    "                        xmax = int(obj[5] * prevVideo.width)\n",
    "                        ymax = int(obj[6] * prevVideo.height)\n",
    "\n",
    "                        ymin = ymin - int(padding * (ymax - ymin))\n",
    "                        in_frame_workers.append((xmin, ymin, xmax, ymax))\n",
    "                        people += 1\n",
    "\n",
    "                violations = detect_workers(in_frame_workers, previous_img)\n",
    "                # Check if detected violations equals previous frames\n",
    "                if violations == prevVideo.currentViolationCount:\n",
    "                    prevVideo.currentViolationCountConfidence += 1\n",
    "                    # If frame threshold is reached, change validated count\n",
    "                    if prevVideo.currentViolationCountConfidence == conf_inFrameViolationsThreshold:\n",
    "                        # If another violation occurred, save image\n",
    "                        if prevVideo.currentViolationCount > prevVideo.prevViolationCount:\n",
    "                            prevVideo.totalViolations += (\n",
    "                                    prevVideo.currentViolationCount - prevVideo.prevViolationCount)\n",
    "                        prevVideo.prevViolationCount = prevVideo.currentViolationCount\n",
    "                else:\n",
    "                    prevVideo.currentViolationCountConfidence = 0\n",
    "                    prevVideo.currentViolationCount = violations\n",
    "\n",
    "                # Check if detected people count equals previous frames\n",
    "                if people == prevVideo.currentPeopleCount:\n",
    "                    prevVideo.currentPeopleCountConfidence += 1\n",
    "                    # If frame threshold is reached, change validated count\n",
    "                    if prevVideo.currentPeopleCountConfidence == conf_inFrameViolationsThreshold:\n",
    "                        prevVideo.currentTotalPeopleCount += (\n",
    "                                prevVideo.currentPeopleCount - prevVideo.prevPeopleCount)\n",
    "                        if prevVideo.currentTotalPeopleCount > prevVideo.prevPeopleCount:\n",
    "                            prevVideo.totalPeopleCount += prevVideo.currentTotalPeopleCount - prevVideo.prevPeopleCount\n",
    "                        prevVideo.prevPeopleCount = prevVideo.currentPeopleCount\n",
    "                else:\n",
    "                    prevVideo.currentPeopleCountConfidence = 0\n",
    "                    prevVideo.currentPeopleCount = people\n",
    "\n",
    "                frame_end_time = datetime.datetime.now()\n",
    "                cv2.putText(previous_img, 'Total people count: ' + str(\n",
    "                    prevVideo.totalPeopleCount), (10, prevVideo.height - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "                cv2.putText(previous_img, 'Current people count: ' + str(\n",
    "                    prevVideo.currentTotalPeopleCount),\n",
    "                            (10, prevVideo.height - 40),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "                cv2.putText(previous_img, 'Total violation count: ' + str(\n",
    "                    prevVideo.totalViolations), (10, prevVideo.height - 70),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "                cv2.putText(previous_img, 'FPS: %0.2fs' % (1 / (\n",
    "                        frame_end_time - prevVideo.frame_start_time).total_seconds()),\n",
    "                            (10, prevVideo.height - 100),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "                cv2.putText(previous_img, 'Inference time: {}ms'.format((infer_end_time).total_seconds()),\n",
    "                            (10, prevVideo.height - 130),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "                cv2.imshow(prevVideo.name, previous_img)\n",
    "                prevVideo.frame_start_time = datetime.datetime.now()\n",
    "\n",
    "            # Swap\n",
    "            currReq, prevReq = prevReq, currReq\n",
    "            previous_img = current_img\n",
    "            prevVideo = currVideo\n",
    "        # Exit if ESC key is pressed\n",
    "        if cv2.waitKey(wait_time) == 27:\n",
    "            print(\"Attempting to stop input files\")\n",
    "            break\n",
    "        if False not in vid_finished:\n",
    "            break\n",
    "    infer_network.clean()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
